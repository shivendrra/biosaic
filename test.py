import os
from src import KMer

current_directory = os.path.dirname(os.path.abspath(__file__))
os.chdir(current_directory)

print("available models: ", get_models)
print("available encodings: ", get_encodings)

token = DNATokenizer(encoding=get_encodings[3])

# with open("data/file4.txt", "r", encoding="utf-8") as f:
#   sequence = f.read()
#   sequence = "".join(line.strip() for line in sequence if line.strip())
#   sequence = sequence.upper()
#   print("sequence length: ", len(sequence))
#   f.close()

sequence = "TCTTACATAGAAAGGAGCGGTATTTGGTATGAATTTATTTGCAACTGACTGCTTGGAAGTTGGCGTACATCTTTCCACGGAAACTATGAAAATACTGGTCAGCCTCTCAGTCATTTCATAAAATCTTGATTTTGTATTACAACAAATTAGGATATTTTCAGTAGAACTGATTGTAAGGCCAGACTGTTGGAATGTAATTCCTTCCCAAACATCTCTCAGGGGCACTTTCCTGAACGGCTGCTGACAGCAGCATTTGAGGACGGTGGGGCGGAGGACATCCTGGGGGGCCTGGCTTCTTGGGAACTGGAGGCTTTGGCCCTTGTCCCACCCCTGCTCCCCTGAGGAGGGAGGCGTGGGGCCCTGGGCTGGCTGCAAGACGTGGAGTGACTGTGGGTCCCCGTGGCCCCTGACATGCTCCCAGGGAACCCAAGAAAAGACTGAGACCCTGTGGTGCCTCCCGCTTTCCATCCGCATTCCATGGCAGGTGAGTCTGATTATTCGAAGGAGGCTGGAGTGTGGGCGGAGGGCAGCGCCAGGTTTCCCAATCAGATTTGCTCAGGGTCCCTCCAGCAGTCCATGCCGCAGAGGCTGTCCCTTGGGGGCCCACGCATCCTAGCCACGGCCTCCTCACGTCCATGCGGGGATTTGCGCCCTGGAAGGAGCCGCCCGGCTGCCTCTCGCCAACATGCAGCACTTCCCTTCCTTTCCATGGAGCACGGTTCCTGTCCCGGGGGTCCATATTGGCCACTGTGGGAGAGAGTCGGGCAGCTGAATTCCCGCAGGTGGGAATGCCAGGGCCCGAGGATGTTGCCCCTGTCCTGAAGGCTGTCGCCCGATCGCTCTATCCAAGGCTGCCCTGGGGCAGCGTCACCTGGGGGTCCTGCGGGGGCTTCTCAGCACAGCATCCAGCACTGCCACCTAGTGTGTTCCCGTCACGTCTCCTCCCCCCGCCTGCACCAGGCACCAGAGACCCGGATGCCAAGGCCTGTCAGCTTCCTCAATGGGAAACTTTTCTTCAGTGAACAAAGCTCTGTTTTATA"
encoded = token.encode(sequence)
decoded = token.decode(encoded)
tokenized = token.tokenize(sequence)

# print(tokenized)
print(encoded)
print(decoded)
print(decoded == sequence)