import os
import biosaic
from biosaic import tokenizer, get_encodings, get_models

current_directory = os.path.dirname(os.path.abspath(__file__))
os.chdir(current_directory)

print("available models: ", get_models)
print("available encodings: ", get_encodings)

token = tokenizer(encoding=get_encodings[2])
print(token.vocab_size)
print(token.vocab)
sequence = "TCTTACATAGAAAGGAGCGGTATTTGGTATGAATTTATTTGCAACTGACTGCTTGGAAGTTGGCGTACATCTTTCCACGGAAACTATGAAAATACTGGTCAGCCTCTCAGTCATTTCATAAAATCTTGATTTTGTATTACAACAAATTAGGATATTTTCAGTAGAACTGATTGTAAGGCCAGACTGTTGGAATGTAATTCCTTCCCAAACATCTCTCAGGGGCACTTTCCTGAACGGCTGCTGACAGCAGCATTTGAGGACGGTGGGGCGGAGGACATCCTGGGGGGCCTGGCTTCTTGGGAACTGGAGGCTTTGGCCCTTGTCCCACCCCTGCTCCCCTGAGGAGGGAGGCGTGGGGCCCTGGGCTGGCTGCAAGACGTGGAGTGACTGTGGGTCCCCGTGGCCCCTGACATGCTCCCAGGGAACCCAAGAAAAGACTGAGACCCTGTGGTGCCTCCCGCTTTCCATCCGCATTCCATGGCAGGTGAGTCTGATTATTCGAAGGAGGCTGGAGTGTGGGCGGAGGGCAGCGCCAGGTTTCCCAATCAGATTTGCTCAGGGTCCCTCCAGCAGTCCATGCCGCAGAGGCTGTCCCTTGGGGGCCCACGCATCCTAGCCACGGCCTCCTCACGTCCATGCGGGGATTTGCGCCCTGGAAGGAGCCGCCCGGCTGCCTCTCGCCAACATGCAGCACTTCCCTTCCTTTCCATGGAGCACGGTTCCTGTCCCGGGGGTCCATATTGGCCACTGTGGGAGAGAGTCGGGCAGCTGAATTCCCGCAGGTGGGAATGCCAGGGCCCGAGGATGTTGCCCCTGTCCTGAAGGCTGTCGCCCGATCGCTCTATCCAAGGCTGCCCTGGGGCAGCGTCACCTGGGGGTCCTGCGGGGGCTTCTCAGCACAGCATCCAGCACTGCCACCTAGTGTGTTCCCGTCACGTCTCCTCCCCCCGCCTGCACCAGGCACCAGAGACCCGGATGCCAAGGCCTGTCAGCTTCCTCAATGGGAAACTTTTCTTCAGTGAACAAAGCTCTGTTTTATA"
encoded = token.encode(sequence)
decoded = token.decode(encoded)
tokenized = token.tokenize(sequence)

print(tokenized)
print(encoded)
print(decoded)
print(decoded == sequence)